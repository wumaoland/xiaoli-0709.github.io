<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>手写数字识别 | 寐烯的小屋</title><meta name="keywords" content="Python,深度学习"><meta name="author" content="寐 烯"><meta name="copyright" content="寐 烯"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="手写数字识别  一、研究课题    目前，图像处理的技术不断地发展。用深度学习的方法对图像进行处理已经成了主流的方 式之一。当前深度学习在图像处理领域的应用可分为三方面:图像处理(基本图像变换)、图像 识别(以神经网络为主流的图像特征提取)和图像生成(以神经风格迁移为代表)。本次大作业尝 试利用深度神经网络来解决实际问题：进行手写数字图像的分类。  二、图像识别原理 2.1MNI">
<meta property="og:type" content="article">
<meta property="og:title" content="手写数字识别">
<meta property="og:url" content="http://1538272824@qq.com/archives/1d11fe8c.html">
<meta property="og:site_name" content="寐烯的小屋">
<meta property="og:description" content="手写数字识别  一、研究课题    目前，图像处理的技术不断地发展。用深度学习的方法对图像进行处理已经成了主流的方 式之一。当前深度学习在图像处理领域的应用可分为三方面:图像处理(基本图像变换)、图像 识别(以神经网络为主流的图像特征提取)和图像生成(以神经风格迁移为代表)。本次大作业尝 试利用深度神经网络来解决实际问题：进行手写数字图像的分类。  二、图像识别原理 2.1MNI">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://1538272824@qq.com/img/article.jpg">
<meta property="article:published_time" content="2022-07-08T04:23:11.000Z">
<meta property="article:modified_time" content="2022-07-12T06:03:11.593Z">
<meta property="article:author" content="寐 烯">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://1538272824@qq.com/img/article.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://1538272824@qq.com/archives/1d11fe8c"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="baidu-site-verification" content="code-sRJNgwIWWn"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '手写数字识别',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-07-12 14:03:11'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/icon_head.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 目录</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 视频</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/article.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">寐烯的小屋</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 目录</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 视频</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">手写数字识别</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-07-08T04:23:11.000Z" title="发表于 2022-07-08 12:23:11">2022-07-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-07-12T06:03:11.593Z" title="更新于 2022-07-12 14:03:11">2022-07-12</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="手写数字识别"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><center>
<font size="5">手写数字识别</font>
</center>
<h4 id="一研究课题">一、研究课题</h4>
<blockquote>
<p>  目前，图像处理的技术不断地发展。用深度学习的方法对图像进行处理已经成了主流的方 式之一。当前深度学习在图像处理领域的应用可分为三方面:图像处理(基本图像变换)、图像 识别(以神经网络为主流的图像特征提取)和图像生成(以神经风格迁移为代表)。本次大作业尝 试利用深度神经网络来解决实际问题：进行手写数字图像的分类。</p>
</blockquote>
<h4 id="二图像识别原理">二、图像识别原理</h4>
<h5 id="mnist数据集">2.1MNIST数据集</h5>
<blockquote>
<p>  MNIST 是机器学习领域最基础、最有名的数据集之一，可被应用于多种场合，如简单实验 和论文研究等等。 该数据集由 0-9 的数字图像构成。训练图像有 6 万张，测试图像有 1 万张，这些图像可以 用于学习和推理。具体的使用过程为：先利用训练图像进行学习，再利用学习到的模型对测试 图像进行正确的模型。</p>
<p><img src="/archives/1d11fe8c.htm/1.png"></p>
<center>
<font size="2;">图 1 MNIST 数据集部分数据示意图</font>
</center>
<p>  MNIST 的图像数据是 28×28pixel 的灰度图像(1 通道），各个像素的取值再 0-255 之间。 每个图像数据都相应地标有“3”“9”“5”等标签。</p>
</blockquote>
<h5 id="深度学习">2.2 深度学习</h5>
<h6 id="神经网络概述">2.2.1 神经网络概述</h6>
<blockquote>
<p>  对于人脑而言，学习就是基于某一条件反射的建立。例如，当眼睛接收到光信号后，会通 过神经系统将信号传播至大脑，引起特定区域的神经细胞活跃，然后这些被激活的神经细胞将 继续影响其他神经细胞，这样不断延伸下渠，直到知道身体做出相应动作，完成条件反射。整 个流程可以大致由下图来表示。</p>
<p><img src="/archives/1d11fe8c.htm/2.png"></p>
<center>
<font size="2;">图2 神经网络的例子
</font></center>
<p>   图中的每一个小圆点即一个神经节点，每个小圆点可以有多个输入，同时可以有一个或多个输出。即我们可以用下列的公式来表示这样一个流程： <span class="math display">\[
f_k(a_{i1},a_{i2},...,a_{in}) = (\sum^n_{j=1}w_ja_{ij})+b_k
\]</span>   到这里我们得到了一个比较简单的神经网络的模拟，但是我们仍需要一个函数来决定何时 激活输入信号的总和。于是我们引入了激活函数。</p>
</blockquote>
<h6 id="激活函数">2.2.2 激活函数</h6>
<blockquote>
<p>  一般来说，神经网络中最常使用的一个激活函数就是 sigmoid 函数，其表达式如下所示： <span class="math display">\[
h(x) = \frac 1{1+e^{-x}}
\]</span>   这个函数的图像为：</p>
<p><img src="/archives/1d11fe8c.htm/3.png"></p>
<center>
<font size="2;">图3 sigmoid函数图像<font>
</font></font></center>
<p>   一个节点在激活状态下输出它的兴奋程度，而在抑制状态下输出接的兴奋程度接近于0。通过调节每一个节点的权重w和阈值b，就可以改变这个神经网络的输出结果。</p>
<p>  输出层的神经元数量需要根据待解决的问题来设定。对于分类问题，输出成的是神经元数量一边设定为类别的数量。在手写字体识别的问题中，预测的结果时0-9数字中的哪一个，因此输出层的神经元设定为10个。</p>
<p>  在手写字体的识别应用中，我们的神经网络结构显然不会如图1一样简单，往往整个网络会含有多个中间层，多达几十几百个输入，最终共有10个输出。以我们数据集中的图片为例，一张28×28pixel大小的图片，将255个像素点的灰度值作为输入，进入含有一层50个节点的中间层，产生0-9的10个输出节点，将会有255<em>50+50</em>10=13250个权重w,60个阈值b需要调整，靠人工进行调整是显然不太现实的，因此需要设计算法让计算机从已有的数据中学习。</p>
</blockquote>
<h6 id="神经网络的学习">2.2.3 神经网络的学习</h6>
<blockquote>
<p>  与其绞劲脑汁从零开始想如何单独识别某个数字的算法，不如考虑通过有效利用数据试法从图像中提取特征量，不断学习，尝试发现待求解的问题的模式。</p>
<p>  在机器学习中，一般将数据分为训练数据和测试数据。神经网络的学习通过某个指标表现现在的状态，即损失函数(loss function)。这个损失函数可以是使用任何函数，在本次的任务中使用的是交叉熵损失(cross entropy error)。其公式如下所示： <span class="math display">\[
E = -\sum_Rt_k\cdot log(y_k)
\]</span>   其中$y_k <span class="math inline">\(是神经网络的输出，\)</span>t_k$是正确解标签。</p>
<p>  机器学习使用训练数据进行学习。因此，计算损失函数时，需要将所有的训练数据作为对象。之前所提到MNIST数据集的训练数据有600000个，如果以全部数据为对象求损失函数的和，那计算需要花费很长的时间。因此，我们将从全部数据中选出一部分(mini-batch)，然后对每个mini-batch进行学习。</p>
<p>  别忘了我们学习的主要任务就是寻找最优参数，即权重w和阈值b。这里的最优参数就是指损失函数取得最小值时w和b的取值。但是之前提到的交叉熵损失比较复杂，很难通过基础的方法求得函数最小值。因此引入了梯度下降算法。</p>
</blockquote>
<h6 id="梯度下降算法">2.2.4 梯度下降算法</h6>
<blockquote>
<p>  通过不断地沿梯度方向前进，逐渐减小函数值的过程就是梯度法（gradient method）。梯度法是解决机器学习中最优化问题的常用方法，特别是在神经网络的学习中经常被使用。下面给出某个参数通过梯度法进行更新的数学公式： <span class="math display">\[
\omega = \omega-\eta\frac{\partial f}{\partial 
\omega}
\]</span>   其中<span class="math inline">\(\omega\)</span>为某参数，<span class="math inline">\(\eta\)</span>为学习率。</p>
</blockquote>
<h6 id="误差反向传播">2.2.5 误差反向传播</h6>
<blockquote>
<p>  为了计算快速的进行梯度的计算，我们利用计算图进行误差反向传播，通过将数据正向和反向地传播，可以高效的计算权重参数地梯度。</p>
</blockquote>
<h5 id="卷积神经网络">2.3 卷积神经网络</h5>
<blockquote>
<p>  本次实验所用的网络结构为卷积神经网络（Convolutional Neural Network,CNN），该网络被用于图像识别、图像分割等多种场合。</p>
<p>  CNN较全连接的神经网络而言，新增了Convolution层和Pooling层。CNN的层的连接顺序时“Convolution-ReLU-Pooling”。具体的CNN流程如下所示：</p>
<p>  在本次实验中的整个结构如下图所示：</p>
<p><img src="/archives/1d11fe8c.htm/4.png"></p>
<center>
<font size="2">图4 手写图片识别CNN结构图</font>
</center>
<p> CNN流程：卷积(Conv2d)-&gt; 激励函数(ReLU)-&gt;池化(MaxPooling)-&gt;卷积(Conv2d)-&gt; 激励函数(ReLU)-&gt;池化(MaxPooling)-&gt;展平多维的卷积成的特征图-&gt;接入全连接层(Linear)-&gt;输出</p>
</blockquote>
<h4 id="三基本配置">三、基本配置</h4>
<blockquote>
<p>实验设备配置：显卡:GeForce GTX 1650.CPU :Intel(R) Core(TM) i5-9300H CPU <span class="citation" data-cites="2.40Ghz">@2.40Ghz</span></p>
<p>实验软件：PyCharm 2020</p>
</blockquote>
<h4 id="四图像预处理">四、图像预处理</h4>
<blockquote>
<p>  因为实际自己写的图片与MNIST的图片有很大的区别，因此要想实现对自己手写的照片的识别首先得将自己手写的照片进行预处理。预处理过程大概分为以下几个部分：</p>
<p>  1、将图片大小转换到28×28pixel大小的图片，可通过cv2.resize进行图片的裁剪操作。</p>
<p>  2、MNIST是灰度图，因此需要将通道数channel转化成1，可通过cv2.cvtColor进行灰度化操作。</p>
<p>  3、图片的背景需要转化成同MNIST一样的黑色，同时将数字的颜色变为白色，以增加识别的准确性。</p>
<p>  4、数字颜色中间深边缘浅，因此需要模拟该渐变色。</p>
<p>实现过程：</p>
<p>  首先通过canny进行边缘检测，得到如图6所示图片。可以发现，“8”被白边给包围，此时将上边界坐标值上移，直到没有遇到白色点停止，此为数字的上边界。同理，可得数字的下边界、左边界以及右边界。然后将数字进行正方形分割，以方便后面的图像像素调整。这边在分割时，在四周各添加了5像素。最终可得到如图7所示的图片。</p>
<p><img src="/archives/1d11fe8c.htm/5.png"></p>
<center>
<font size="2">图5 手写的原始图像</font>
</center>
<p><img src="/archives/1d11fe8c.htm/6.png"></p>
<center>
<font size="2">图6 canny 边缘提取图 </font>
</center>
<p><img src="/archives/1d11fe8c.htm/7.png"></p>
<center>
<font size="2">图7 正方形分割后图片</font>
</center>
<p>  接下来就是对裁剪出来的小图进行处理，进行灰度化和高斯滤波处理，然后在对图像进行大小转换。大小转换完成后，就是要完成把灰度图转换成背景为0，然后数字变成白色的图片。最后得到的图像如图8所示。</p>
<p><img src="/archives/1d11fe8c.htm/8.png"></p>
<center>
<font size="2">图8 处理后可将进行预测的图像</font>
</center>
</blockquote>
<h4 id="五实验代码">五、实验代码</h4>
<blockquote>
<p>main.py</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练+测试</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> processing <span class="keyword">import</span> image_preprocessing</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">1</span>)  <span class="comment"># 使用随机化种子使神经网络的初始化每次都相同</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 超参数</span></span><br><span class="line">EPOCH = <span class="number">1</span>  <span class="comment"># 训练整批数据的次数</span></span><br><span class="line">BATCH_SIZE = <span class="number">50</span></span><br><span class="line">LR = <span class="number">0.001</span>  <span class="comment"># 学习率</span></span><br><span class="line">DOWNLOAD_MNIST = <span class="literal">True</span>  <span class="comment"># 表示还没有下载数据集，如果数据集下载好了就写False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载mnist手写数据集</span></span><br><span class="line">train_data = torchvision.datasets.MNIST(</span><br><span class="line">    root=<span class="string">&#x27;./data/&#x27;</span>,  <span class="comment"># 保存或提取的位置  会放在当前文件夹中</span></span><br><span class="line">    train=<span class="literal">True</span>,  <span class="comment"># true说明是用于训练的数据，false说明是用于测试的数据</span></span><br><span class="line">    transform=torchvision.transforms.ToTensor(),  <span class="comment"># 转换PIL.Image or numpy.ndarray</span></span><br><span class="line"></span><br><span class="line">    download=DOWNLOAD_MNIST,  <span class="comment"># 已经下载了就不需要下载了</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_data = torchvision.datasets.MNIST(</span><br><span class="line">    root=<span class="string">&#x27;./data/&#x27;</span>,</span><br><span class="line">    train=<span class="literal">False</span>  <span class="comment"># 表明是测试集</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批训练 50个samples， 1  channel，28x28 (50,1,28,28)</span></span><br><span class="line"><span class="comment"># Torch中的DataLoader是用来包装数据的工具，它能帮我们有效迭代数据，这样就可以进行批训练</span></span><br><span class="line">train_loader = Data.DataLoader(</span><br><span class="line">    dataset=train_data,</span><br><span class="line">    batch_size=BATCH_SIZE,</span><br><span class="line">    shuffle=<span class="literal">True</span>  <span class="comment"># 是否打乱数据，一般都打乱</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行测试</span></span><br><span class="line"><span class="comment"># 为节约时间，测试时只测试前2000个</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">length_test = <span class="number">2000</span></span><br><span class="line">test_x = torch.unsqueeze(test_data.train_data, dim=<span class="number">1</span>).<span class="built_in">type</span>(torch.FloatTensor)[:<span class="number">2000</span>] / <span class="number">255</span></span><br><span class="line"><span class="comment"># torch.unsqueeze(a) 是用来对数据维度进行扩充，这样shape就从(2000,28,28)-&gt;(2000,1,28,28)</span></span><br><span class="line"><span class="comment"># 图像的pixel本来是0到255之间，除以255对图像进行归一化使取值范围在(0,1)</span></span><br><span class="line">test_y = test_data.test_labels[:<span class="number">2000</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用class类来建立CNN模型</span></span><br><span class="line"><span class="comment"># CNN流程：卷积(Conv2d)-&gt; 激励函数(ReLU)-&gt;池化(MaxPooling)-&gt;</span></span><br><span class="line"><span class="comment">#        卷积(Conv2d)-&gt; 激励函数(ReLU)-&gt;池化(MaxPooling)-&gt;</span></span><br><span class="line"><span class="comment">#        展平多维的卷积成的特征图-&gt;接入全连接层(Linear)-&gt;输出</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CNN</span>(nn.Module):  <span class="comment"># 我们建立的CNN继承nn.Module这个模块</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line">        <span class="comment"># 建立第一个卷积(Conv2d)-&gt; 激励函数(ReLU)-&gt;池化(MaxPooling)</span></span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            <span class="comment"># 第一个卷积con2d</span></span><br><span class="line">            nn.Conv2d(  <span class="comment"># 输入图像大小(1,28,28)</span></span><br><span class="line">                in_channels=<span class="number">1</span>,  <span class="comment"># 输入图片的高度，因为minist数据集是灰度图像只有一个通道</span></span><br><span class="line">                out_channels=<span class="number">16</span>,  <span class="comment"># n_filters 卷积核的高度</span></span><br><span class="line">                kernel_size=<span class="number">5</span>,  <span class="comment"># filter size 卷积核的大小 也就是长x宽=5x5</span></span><br><span class="line">                stride=<span class="number">1</span>,  <span class="comment"># 步长</span></span><br><span class="line">                padding=<span class="number">2</span>,  <span class="comment"># 想要con2d输出的图片长宽不变，就进行补零操作 padding = (kernel_size-1)/2</span></span><br><span class="line">            ),  <span class="comment"># 输出图像大小(16,28,28)</span></span><br><span class="line">            <span class="comment"># 激活函数</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            <span class="comment"># 池化，下采样</span></span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>),  <span class="comment"># 在2x2空间下采样</span></span><br><span class="line">            <span class="comment"># 输出图像大小(16,14,14)</span></span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 建立第二个卷积(Conv2d)-&gt; 激励函数(ReLU)-&gt;池化(MaxPooling)</span></span><br><span class="line">        self.conv2 = nn.Sequential(</span><br><span class="line">            <span class="comment"># 输入图像大小(16,14,14)</span></span><br><span class="line">            nn.Conv2d(  <span class="comment"># 也可以直接简化写成nn.Conv2d(16,32,5,1,2)</span></span><br><span class="line">                in_channels=<span class="number">16</span>,</span><br><span class="line">                out_channels=<span class="number">32</span>,</span><br><span class="line">                kernel_size=<span class="number">5</span>,</span><br><span class="line">                stride=<span class="number">1</span>,</span><br><span class="line">                padding=<span class="number">2</span></span><br><span class="line">            ),</span><br><span class="line">            <span class="comment"># 输出图像大小 (32,14,14)</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            <span class="comment"># 输出图像大小(32,7,7)</span></span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 建立全卷积连接层</span></span><br><span class="line">        self.out = nn.Linear(<span class="number">32</span> * <span class="number">7</span> * <span class="number">7</span>, <span class="number">10</span>)  <span class="comment"># 输出是10个类</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 下面定义x的传播路线</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)  <span class="comment"># x先通过conv1</span></span><br><span class="line">        x = self.conv2(x)  <span class="comment"># 再通过conv2</span></span><br><span class="line">        <span class="comment"># 把每一个批次的每一个输入都拉成一个维度，即(batch_size,32*7*7)</span></span><br><span class="line">        <span class="comment"># 因为pytorch里特征的形式是[bs,channel,h,w]，所以x.size(0)就是batchsize</span></span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)  <span class="comment"># view就是把x弄成batchsize行个tensor</span></span><br><span class="line">        output = self.out(x)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cnn = CNN()</span><br><span class="line"><span class="built_in">print</span>(cnn)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line"><span class="comment"># 把x和y 都放入Variable中，然后放入cnn中计算output，最后再计算误差</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化器选择Adam</span></span><br><span class="line">optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)</span><br><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line">loss_func = nn.CrossEntropyLoss()  <span class="comment"># 目标标签是one-hotted</span></span><br><span class="line">acc = []</span><br><span class="line">ls = []</span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line"><span class="comment"># for epoch in range(EPOCH):</span></span><br><span class="line"><span class="comment">#     for step, (b_x, b_y) in enumerate(train_loader):  # 分配batch data</span></span><br><span class="line"><span class="comment">#         output = cnn(b_x)  # 先将数据放到cnn中计算output</span></span><br><span class="line"><span class="comment">#         loss = loss_func(output, b_y)  # 输出和真实标签的loss，二者位置不可颠倒</span></span><br><span class="line"><span class="comment">#         optimizer.zero_grad()  # 清除之前学到的梯度的参数</span></span><br><span class="line"><span class="comment">#         loss.backward()  # 反向传播，计算梯度</span></span><br><span class="line"><span class="comment">#         optimizer.step()  # 应用梯度</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#         if step % 50 == 0:</span></span><br><span class="line"><span class="comment">#             test_output = cnn(test_x)</span></span><br><span class="line"><span class="comment">#             pred_y = torch.max(test_output, 1)[1].data.numpy()</span></span><br><span class="line"><span class="comment">#             accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))</span></span><br><span class="line"><span class="comment">#             print(&#x27;Epoch: &#x27;, epoch, &#x27;| train loss: %.4f&#x27; % loss.data.numpy(), &#x27;| test accuracy: %.2f&#x27; % accuracy)</span></span><br><span class="line"><span class="comment">#             acc.append(accuracy)</span></span><br><span class="line"><span class="comment">#             ls.append(loss.data.numpy())</span></span><br><span class="line"><span class="comment">#     len_accuracy = len(acc)</span></span><br><span class="line"><span class="comment">#     len_ls = len(ls)</span></span><br><span class="line"><span class="comment">#     plt.figure(1)</span></span><br><span class="line"><span class="comment">#     plt.plot(np.arange(len_accuracy),acc)</span></span><br><span class="line"><span class="comment">#     plt.title(&#x27;accuracy picutre&#x27;)</span></span><br><span class="line"><span class="comment">#     plt.xlabel(&#x27;step&#x27;)</span></span><br><span class="line"><span class="comment">#     plt.ylabel(&#x27;Accuracy&#x27;)</span></span><br><span class="line"><span class="comment">#     plt.show()</span></span><br><span class="line"><span class="comment">#     plt.figure(2)</span></span><br><span class="line"><span class="comment">#     plt.plot(np.arange(len_ls),ls)</span></span><br><span class="line"><span class="comment">#     plt.title(&#x27;loss picutre&#x27;)</span></span><br><span class="line"><span class="comment">#     plt.xlabel(&#x27;step&#x27;)</span></span><br><span class="line"><span class="comment">#     plt.ylabel(&#x27;loss&#x27;)</span></span><br><span class="line"><span class="comment">#     plt.show()</span></span><br><span class="line"><span class="comment"># torch.save(cnn.state_dict(), &#x27;cnn2.pkl&#x27;)#保存模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型，调用时需将前面训练及保存模型的代码注释掉，否则会再训练一遍</span></span><br><span class="line">cnn.load_state_dict(torch.load(<span class="string">&#x27;cnn2.pkl&#x27;</span>))</span><br><span class="line">cnn.<span class="built_in">eval</span>()</span><br><span class="line"><span class="comment"># print 10 predictions from test data</span></span><br><span class="line">inputs_init = image_preprocessing()</span><br><span class="line">inputs = inputs_init.reshape([-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">inputs = torch.from_numpy(inputs)</span><br><span class="line">inputs = inputs.<span class="built_in">float</span>()</span><br><span class="line"><span class="comment"># inputs = test_x[500:516]  # 测试32个数据</span></span><br><span class="line">test_output = cnn(inputs)</span><br><span class="line">pred_y = torch.<span class="built_in">max</span>(test_output, <span class="number">1</span>)[<span class="number">1</span>].data.numpy()</span><br><span class="line"><span class="built_in">print</span>( <span class="string">&#x27;预测结果为&#x27;</span>,pred_y)  <span class="comment"># 打印识别后的数字</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = torchvision.utils.make_grid(inputs)</span><br><span class="line">img = img.numpy().transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面三行为改变图片的亮度</span></span><br><span class="line"><span class="comment"># std = [0.5, 0.5, 0.5]</span></span><br><span class="line"><span class="comment"># mean = [0.5, 0.5, 0.5]</span></span><br><span class="line"><span class="comment"># img = img * std + mean</span></span><br><span class="line">cv2.namedWindow(<span class="string">&#x27;win&#x27;</span>,<span class="number">0</span>)</span><br><span class="line">cv2.imshow(<span class="string">&#x27;win&#x27;</span>, img)  <span class="comment"># opencv显示需要识别的数据图片</span></span><br><span class="line">key_pressed = cv2.waitKey(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>processing.py</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image_preprocessing</span>():</span><br><span class="line">	<span class="comment"># 读取图片</span></span><br><span class="line">	img = cv2.imread(<span class="string">&quot;./image/0.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># =====================图像处理======================== #</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 转换成灰度图像</span></span><br><span class="line">	gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 进行高斯滤波</span></span><br><span class="line">	gauss_img = cv2.GaussianBlur(gray_img, (<span class="number">5</span>, <span class="number">5</span>), <span class="number">0</span>, <span class="number">0</span>, cv2.BORDER_DEFAULT)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 边缘检测</span></span><br><span class="line">	img_edge1 = cv2.Canny(gauss_img, <span class="number">100</span>, <span class="number">200</span>)</span><br><span class="line">	<span class="comment"># cv2.imshow(&#x27;win&#x27;, img_edge1)</span></span><br><span class="line">	<span class="comment"># key_pressed = cv2.waitKey(0)</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># ==================================================== #</span></span><br><span class="line">	<span class="comment"># =====================图像分割======================== #</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 获取原始图像的宽和高</span></span><br><span class="line">	high = img.shape[<span class="number">0</span>]</span><br><span class="line">	width = img.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 分别初始化高和宽的和</span></span><br><span class="line">	add_width = np.zeros(high, dtype=<span class="built_in">int</span>)</span><br><span class="line">	add_high = np.zeros(width, dtype=<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 计算每一行的灰度图的值的和</span></span><br><span class="line">	<span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(high):</span><br><span class="line">		<span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(width):</span><br><span class="line">			add_width[h] = add_width[h] + img_edge1[h][w]</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 计算每一列的值的和</span></span><br><span class="line">	<span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(width):</span><br><span class="line">		<span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(high):</span><br><span class="line">			add_high[w] = add_high[w] + img_edge1[h][w]</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 初始化上下边界为宽度总值最大的值的索引</span></span><br><span class="line">	acount_high_up = np.argmax(add_width)</span><br><span class="line">	acount_high_down = np.argmax(add_width)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 将上边界坐标值上移，直到没有遇到白色点停止，此为数字的上边界</span></span><br><span class="line">	<span class="keyword">while</span> add_width[acount_high_up] != <span class="number">0</span>:</span><br><span class="line">		acount_high_up = acount_high_up + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 将下边界坐标值下移，直到没有遇到白色点停止，此为数字的下边界</span></span><br><span class="line">	<span class="keyword">while</span> add_width[acount_high_down] != <span class="number">0</span>:</span><br><span class="line">		acount_high_down = acount_high_down - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 初始化左右边界为宽度总值最大的值的索引</span></span><br><span class="line">	acount_width_left = np.argmax(add_high)</span><br><span class="line">	acount_width_right = np.argmax(add_high)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 将左边界坐标值左移，直到没有遇到白色点停止，此为数字的左边界</span></span><br><span class="line">	<span class="keyword">while</span> add_high[acount_width_left] != <span class="number">0</span>:</span><br><span class="line">		acount_width_left = acount_width_left - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 将右边界坐标值右移，直到没有遇到白色点停止，此为数字的右边界</span></span><br><span class="line">	<span class="keyword">while</span> add_high[acount_width_right] != <span class="number">0</span>:</span><br><span class="line">		acount_width_right = acount_width_right + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 求出宽和高的间距</span></span><br><span class="line">	width_spacing = acount_width_right - acount_width_left</span><br><span class="line">	high_spacing = acount_high_up - acount_high_down</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 求出宽和高的间距差</span></span><br><span class="line">	poor = width_spacing - high_spacing</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 将数字进行正方形分割，目的是方便之后进行图像压缩</span></span><br><span class="line">	<span class="keyword">if</span> poor &gt; <span class="number">0</span>:</span><br><span class="line">		tailor_image = img[acount_high_down - poor // <span class="number">2</span> - <span class="number">5</span>:acount_high_up + poor - poor // <span class="number">2</span> + <span class="number">5</span>,</span><br><span class="line">					   acount_width_left - <span class="number">5</span>:acount_width_right + <span class="number">5</span>]</span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		tailor_image = img[acount_high_down - <span class="number">5</span>:acount_high_up + <span class="number">5</span>,</span><br><span class="line">					   acount_width_left + poor // <span class="number">2</span> - <span class="number">5</span>:acount_width_right - poor + poor // <span class="number">2</span> + <span class="number">5</span>]</span><br><span class="line">	<span class="comment"># cv2.imshow(&#x27;win&#x27;, tailor_image)</span></span><br><span class="line">	<span class="comment"># key_pressed = cv2.waitKey(0)</span></span><br><span class="line">	<span class="comment"># ==================================================== #</span></span><br><span class="line">	<span class="comment"># ======================小图处理======================= #</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># 将裁剪后的图片进行灰度化</span></span><br><span class="line">	gray_img = cv2.cvtColor(tailor_image, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 高斯去噪</span></span><br><span class="line">	gauss_img = cv2.GaussianBlur(gray_img, (<span class="number">5</span>, <span class="number">5</span>), <span class="number">0</span>, <span class="number">0</span>, cv2.BORDER_DEFAULT)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 将图像形状调整到28*28大小</span></span><br><span class="line">	zoom_image = cv2.resize(gauss_img, (<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 获取图像的高和宽</span></span><br><span class="line">	high = zoom_image.shape[<span class="number">0</span>]</span><br><span class="line">	wide = zoom_image.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 将图像每个点的灰度值进行阈值比较</span></span><br><span class="line">	<span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(high):</span><br><span class="line">		<span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(wide):</span><br><span class="line"></span><br><span class="line">			<span class="comment"># 若灰度值大于100，则判断为背景并赋值0，否则将深灰度值变白处理</span></span><br><span class="line">			<span class="keyword">if</span> zoom_image[h][w] &gt; <span class="number">100</span>:</span><br><span class="line">				zoom_image[h][w] = <span class="number">0</span></span><br><span class="line">			<span class="keyword">else</span>:</span><br><span class="line">				zoom_image[h][w] = <span class="number">255</span> - zoom_image[h][w]</span><br><span class="line"></span><br><span class="line">	<span class="comment"># ==================================================== #</span></span><br><span class="line">	<span class="comment"># cv2.imshow(&#x27;win&#x27;, zoom_image)</span></span><br><span class="line">	<span class="comment"># key_pressed = cv2.waitKey(0)</span></span><br><span class="line">	<span class="keyword">return</span> zoom_image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">	image_preprocessing()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="六实验结果">六、实验结果</h4>
<blockquote>
<p>  文件目录如下所示：</p>
</blockquote>
<p><img src="/archives/1d11fe8c.htm/9.png"></p>
<center>
<font size="2">图9 文件目录图</font>
</center>
<blockquote>
<p>  其中processing.py为图像处理部分，对手机拍摄的图片进行相应的处理以达到能够由训练出俩的模型进行判别。</p>
<p>  运行test2.py程序，初次会进行数据集的下载，随后自行进行训练。训练过程中会实时给出训练的精度以及loss,并在训练后绘制除相应的曲线。</p>
</blockquote>
<p><img src="/archives/1d11fe8c.htm/10.png"></p>
<center>
<font size="2"> 图10 训练过程中控制台输出示意图</font>
</center>
<p><img src="/archives/1d11fe8c.htm/11.png"></p>
<blockquote>
<p>  训练结束后，会自动保存模型，并且利用已保存的模型对自己的手写数字进行识别。下面给出几张预测的结果图。</p>
</blockquote>
<p><img src="/archives/1d11fe8c.htm/12.png"></p>
<h4 id="七结果分析和研究总结">七、结果分析和研究总结</h4>
<p>  从实验结果可以看出，对于手写比较规范的数字而言识别的还是比较好的。对于一些不太规范的，例如图14的“4”，可能对于人脑而言也不太能区分是“4”还是“6”，而对于图15来说，可能就是模型存在的一些缺陷的部分了。在实际的操作过程中，其实从拍照照片到处理后能够进行预测的图，也就是上图中那些黑白图像，是有一些差距的。由于图像处理的不完善，很多图片甚至无法进行预测。但是就能够预测的图片而言，效果还是很不错的。</p>
<p>  对于MNIST数据集而言，使用预测集的精度是相当高的，基本都能够正确的进行预测。同时，在试图将自己拍摄的照片也能通过模型来进行预测的时候，遇到了不少的问题。在查询了很多资料后，也是大致将功能实现了出来，虽然最后由于对图片裁剪和分割的效果不是很好，导致一些数字识别效果较差，但对于字迹工整完美的字体还是能够起到很好的识别效果的。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://1538272824@qq.com">寐 烯</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://1538272824@qq.com/archives/1d11fe8c.html">http://1538272824@qq.com/archives/1d11fe8c.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://1538272824@qq.com" target="_blank">寐烯的小屋</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post_share"><div class="social-share" data-image="/img/article.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/archives/63f0ebc.html"><img class="prev-cover" src="/img/shaonv.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">力扣刷题记录--删除排序数组中的重复项（一）</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/icon_head.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">寐 烯</div><div class="author-info__description">过于低调~</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E7%A0%94%E7%A9%B6%E8%AF%BE%E9%A2%98"><span class="toc-number">1.</span> <span class="toc-text">一、研究课题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E5%8E%9F%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text">二、图像识别原理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#mnist%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.1.</span> <span class="toc-text">2.1MNIST数据集</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 深度学习</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A6%82%E8%BF%B0"><span class="toc-number">2.2.1.</span> <span class="toc-text">2.2.1 神经网络概述</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">2.2.2.</span> <span class="toc-text">2.2.2 激活函数</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.2.3.</span> <span class="toc-text">2.2.3 神经网络的学习</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95"><span class="toc-number">2.2.4.</span> <span class="toc-text">2.2.4 梯度下降算法</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E8%AF%AF%E5%B7%AE%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-number">2.2.5.</span> <span class="toc-text">2.2.5 误差反向传播</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 卷积神经网络</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%89%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE"><span class="toc-number">3.</span> <span class="toc-text">三、基本配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9B%E5%9B%BE%E5%83%8F%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">4.</span> <span class="toc-text">四、图像预处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%94%E5%AE%9E%E9%AA%8C%E4%BB%A3%E7%A0%81"><span class="toc-number">5.</span> <span class="toc-text">五、实验代码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%AD%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">6.</span> <span class="toc-text">六、实验结果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%83%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90%E5%92%8C%E7%A0%94%E7%A9%B6%E6%80%BB%E7%BB%93"><span class="toc-number">7.</span> <span class="toc-text">七、结果分析和研究总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/archives/d710a438.html" title="力扣刷题记录（二）——买卖股票的最佳时机II"><img src="/img/article3.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="力扣刷题记录（二）——买卖股票的最佳时机II"/></a><div class="content"><a class="title" href="/archives/d710a438.html" title="力扣刷题记录（二）——买卖股票的最佳时机II">力扣刷题记录（二）——买卖股票的最佳时机II</a><time datetime="2022-07-12T00:24:40.000Z" title="发表于 2022-07-12 08:24:40">2022-07-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/archives/63f0ebc.html" title="力扣刷题记录--删除排序数组中的重复项（一）"><img src="/img/shaonv.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="力扣刷题记录--删除排序数组中的重复项（一）"/></a><div class="content"><a class="title" href="/archives/63f0ebc.html" title="力扣刷题记录--删除排序数组中的重复项（一）">力扣刷题记录--删除排序数组中的重复项（一）</a><time datetime="2022-07-11T00:28:36.000Z" title="发表于 2022-07-11 08:28:36">2022-07-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/archives/1d11fe8c.html" title="手写数字识别"><img src="/img/article.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="手写数字识别"/></a><div class="content"><a class="title" href="/archives/1d11fe8c.html" title="手写数字识别">手写数字识别</a><time datetime="2022-07-08T04:23:11.000Z" title="发表于 2022-07-08 12:23:11">2022-07-08</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By 寐 烯</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>